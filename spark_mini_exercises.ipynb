{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a69bc2",
   "metadata": {},
   "source": [
    "# Spark API Mini Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b806d9fd",
   "metadata": {},
   "source": [
    "#### Copy the code below to create a pandas dataframe with 20 rows and 3 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512505a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d738997",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4206de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>group</th>\n",
       "      <th>abool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.712391</td>\n",
       "      <td>z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753766</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.044503</td>\n",
       "      <td>z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.451812</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.345102</td>\n",
       "      <td>z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n group  abool\n",
       "0 -0.712391     z  False\n",
       "1  0.753766     x  False\n",
       "2 -0.044503     z  False\n",
       "3  0.451812     y  False\n",
       "4  1.345102     z  False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee5cc33",
   "metadata": {},
   "source": [
    "### 1. Spark Dataframe Basics\n",
    "\n",
    "1. Use the starter code above to create a pandas dataframe.\n",
    "2. Convert the pandas dataframe to a spark dataframe. From this point\n",
    "   forward, do all of your work with the spark dataframe, not the pandas\n",
    "   dataframe.\n",
    "3. Show the first 3 rows of the dataframe.\n",
    "4. Show the first 7 rows of the dataframe.\n",
    "5. View a summary of the data using `.describe`.\n",
    "6. Use `.select` to create a new dataframe with just the `n` and `abool`\n",
    "   columns. View the first 5 rows of this dataframe.\n",
    "7. Use `.select` to create a new dataframe with just the `group` and `abool`\n",
    "   columns. View the first 5 rows of this dataframe.\n",
    "8. Use `.select` to create a new dataframe with the `group` column and the\n",
    "   `abool` column renamed to `a_boolean_value`. Show the first 3 rows of\n",
    "   this dataframe.\n",
    "9. Use `.select` to create a new dataframe with the `group` column and the\n",
    "   `n` column renamed to `a_numeric_value`. Show the first 6 rows of this\n",
    "   dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8073ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78252a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[n: double, group: string, abool: boolean]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8ddcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First three rows:\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79aa3216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First 7 rows:\n",
    "df.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339a3b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, n: string, group: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary using .describe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d1039cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+\n",
      "|summary|                 n|group|\n",
      "+-------+------------------+-----+\n",
      "|  count|                20|   20|\n",
      "|   mean|0.3664026449885216| null|\n",
      "| stddev|0.8905322898155363| null|\n",
      "|    min|-1.261605945319069|    x|\n",
      "|    max|2.1503829673811126|    z|\n",
      "+-------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78048062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                   n|abool|\n",
      "+--------------------+-----+\n",
      "|  -0.712390662050588|false|\n",
      "|   0.753766378659703|false|\n",
      "|-0.04450307833805...|false|\n",
      "| 0.45181233874578974|false|\n",
      "|  1.3451017084510097|false|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use .select to create a new dataframe with just the n and abool columns. View the first 5 rows of this dataframe.\n",
    "df.select(df.n, df.abool).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e85ca44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|group|abool|\n",
      "+-----+-----+\n",
      "|    z|false|\n",
      "|    x|false|\n",
      "|    z|false|\n",
      "|    y|false|\n",
      "|    z|false|\n",
      "+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use .select to create a new dataframe with just the group and abool columns. View the first 5 rows of this dataframe.\n",
    "df.select(df.group, df.abool).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1baa2f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|group|a_boolean_value|\n",
      "+-----+---------------+\n",
      "|    z|          false|\n",
      "|    x|          false|\n",
      "|    z|          false|\n",
      "|    y|          false|\n",
      "|    z|          false|\n",
      "+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use .select to create a new dataframe with the group column and the abool column renamed to a_boolean_value. \n",
    "# Show the first 3 rows of this dataframe.\n",
    "df.select(df.group, df.abool.alias('a_boolean_value')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96748a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56dca172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|group|                   n|\n",
      "+-----+--------------------+\n",
      "|    z|  -0.712390662050588|\n",
      "|    x|   0.753766378659703|\n",
      "|    z|-0.04450307833805...|\n",
      "|    y| 0.45181233874578974|\n",
      "|    z|  1.3451017084510097|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use .select to create a new dataframe with the group column and the n column renamed to a_numeric_value. \n",
    "# Show the first 6 rows of this dataframe.\n",
    "df.select(df.group, df.n).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5587d3",
   "metadata": {},
   "source": [
    "### Column Manipulation\n",
    "\n",
    "1. Use the starter code above to re-create a spark dataframe. Store the\n",
    "   spark dataframe in a varaible named `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55226804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139f8a7",
   "metadata": {},
   "source": [
    "2. Use `.select` to add 4 to the `n` column. Show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34bdea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                   n|           (n + 4)|\n",
      "+--------------------+------------------+\n",
      "|  -0.712390662050588|3.2876093379494122|\n",
      "|   0.753766378659703| 4.753766378659703|\n",
      "|-0.04450307833805...|3.9554969216619464|\n",
      "| 0.45181233874578974|  4.45181233874579|\n",
      "|  1.3451017084510097|5.3451017084510095|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n, df.n + 4).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6b150",
   "metadata": {},
   "source": [
    "3. Subtract 5 from the `n` column and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e84c2d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                   n|            (n - 5)|\n",
      "+--------------------+-------------------+\n",
      "|  -0.712390662050588| -5.712390662050588|\n",
      "|   0.753766378659703| -4.246233621340297|\n",
      "|-0.04450307833805...| -5.044503078338053|\n",
      "| 0.45181233874578974|  -4.54818766125421|\n",
      "|  1.3451017084510097|-3.6548982915489905|\n",
      "+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n, df.n - 5).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3962fe",
   "metadata": {},
   "source": [
    "4. Multiply the `n` column by 2. View the results along with the original\n",
    "   numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee77c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                   n|                  n2|\n",
      "+--------------------+--------------------+\n",
      "|  -0.712390662050588|  -1.424781324101176|\n",
      "|   0.753766378659703|   1.507532757319406|\n",
      "|-0.04450307833805...|-0.08900615667610691|\n",
      "| 0.45181233874578974|  0.9036246774915795|\n",
      "|  1.3451017084510097|  2.6902034169020195|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n, (df.n * 2).alias(\"n2\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f822a5",
   "metadata": {},
   "source": [
    "5. Add a new column named `n2` that is the `n` value multiplied by -1. Show\n",
    "   the first 4 rows of your dataframe. You should see the original `n` value\n",
    "   as well as `n2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadbd00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c017d807",
   "metadata": {},
   "source": [
    "6. Add a new column named `n3` that is the n value squared. Show the first 5\n",
    "   rows of your dataframe. You should see both `n`, `n2`, and `n3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b38941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34a43985",
   "metadata": {},
   "source": [
    "7. What happens when you run the code below?\n",
    "\n",
    "    ```python\n",
    "    df.group + df.abool\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc31be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73837bbe",
   "metadata": {},
   "source": [
    "8. What happens when you run the code below? What is the difference between\n",
    "   this and the previous code sample?\n",
    "\n",
    "    ```python\n",
    "    df.select(df.group + df.abool)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd56699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fb8129b",
   "metadata": {},
   "source": [
    "9. Try adding various other columns together. What are the results of\n",
    "   combining the different data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e670793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ccf4a8c",
   "metadata": {},
   "source": [
    "### 1. Type casting\n",
    "\n",
    "1. Use the starter code above to re-create a spark dataframe.\n",
    "\n",
    "1. Use `.printSchema` to view the datatypes in your dataframe.\n",
    "\n",
    "1. Use `.dtypes` to view the datatypes in your dataframe.\n",
    "\n",
    "1. What is the difference between the two code samples below?\n",
    "\n",
    "    ```python\n",
    "    df.abool.cast('int')\n",
    "    ```\n",
    "\n",
    "    ```python\n",
    "    df.select(df.abool.cast('int')).show()\n",
    "    ```\n",
    "\n",
    "1. Use `.select` and `.cast` to convert the `abool` column to an integer\n",
    "   type. View the results.\n",
    "1. Convert the `group` column to a integer data type and view the results.\n",
    "   What happens?\n",
    "1. Convert the `n` column to a integer data type and view the results. What\n",
    "   happens?\n",
    "1. Convert the `abool` column to a string data type and view the results.\n",
    "   What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae68581",
   "metadata": {},
   "source": [
    "### 1. Built-in Functions\n",
    "\n",
    "1. Use the starter code above to re-create a spark dataframe.\n",
    "1. Import the necessary functions from `pyspark.sql.functions`\n",
    "1. Find the highest `n` value.\n",
    "1. Find the lowest `n` value.\n",
    "1. Find the average `n` value.\n",
    "1. Use `concat` to change the `group` column to say, e.g. \"Group: x\" or\n",
    "   \"Group: y\"\n",
    "1. Use `concat` to combine the `n` and `group` columns to produce results\n",
    "   that look like this: \"x: -1.432\" or \"z: 2.352\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a191f52",
   "metadata": {},
   "source": [
    "### 1. When / Otherwise\n",
    "\n",
    "1. Use the starter code above to re-create a spark dataframe.\n",
    "1. Use `when` and `.otherwise` to create a column that contains the text \"It\n",
    "   is true\" when `abool` is true and \"It is false\"\" when `abool` is false.\n",
    "1. Create a column that contains 0 if n is less than 0, otherwise, the\n",
    "   original n value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028df784",
   "metadata": {},
   "source": [
    "### 1. Filter / Where\n",
    "\n",
    "1. Use the starter code above to re-create a spark dataframe.\n",
    "1. Use `.filter` or `.where` to select just the rows where the group is `y`\n",
    "   and view the results.\n",
    "1. Select just the columns where the `abool` column is false and view the\n",
    "   results.\n",
    "1. Find the columns where the `group` column is *not* `y`.\n",
    "1. Find the columns where `n` is positive.\n",
    "1. Find the columns where `abool` is true and the `group` column is `z`.\n",
    "1. Find the columns where `abool` is true or the `group` column is `z`.\n",
    "1. Find the columns where `abool` is false and `n` is less than 1\n",
    "1. Find the columns where `abool` is false or `n` is less than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067fac7d",
   "metadata": {},
   "source": [
    "### 1. Sorting\n",
    "\n",
    "1. Use the starter code above to re-create a spark dataframe.\n",
    "1. Sort by the `n` value.\n",
    "1. Sort by the `group` value, both ascending and descending.\n",
    "1. Sort by the group value first, then, within each group, sort by `n`\n",
    "   value.\n",
    "1. Sort by `abool`, `group`, and `n`. Does it matter in what order you\n",
    "   specify the columns when sorting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cf11e",
   "metadata": {},
   "source": [
    "### 1. Spark SQL\n",
    "\n",
    "1. Use the starter code above to re-create a spark dataframe.\n",
    "1. Turn your dataframe into a table that can be queried with spark SQL. Name\n",
    "   the table `my_df`. Answer the rest of the questions in this section with\n",
    "   a spark sql query (`spark.sql`) against `my_df`. After each step, view\n",
    "   the first 7 records from the dataframe.\n",
    "1. Write a query that shows all of the columns from your dataframe.\n",
    "1. Write a query that shows just the `n` and `abool` columns from the\n",
    "   dataframe.\n",
    "1. Write a query that shows just the `n` and `group` columns. Rename the\n",
    "   `group` column to `g`.\n",
    "1. Write a query that selects `n`, and creates two new columns: `n2`, the\n",
    "   original `n` values halved, and `n3`: the original n values minus 1.\n",
    "1. What happens if you make a SQL syntax error in your query?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8b3e7f",
   "metadata": {},
   "source": [
    "### 1. Aggregating\n",
    "\n",
    "1. What is the average `n` value for each group in the `group` column?\n",
    "1. What is the maximum `n` value for each group in the `group` column?\n",
    "1. What is the minimum `n` value by `abool`?\n",
    "1. What is the average `n` value for each unique combination of the `group`\n",
    "   and `abool` column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e31a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Revisit the exercises for the [pandas dataframes lesson][1] and [the advanced\n",
    "dataframes lesson][2]. Complete the exercises, but convert the pandas dataframes\n",
    "to spark dataframes first in order to practice using the spark api.\n",
    "\n",
    "[1]: https://ds.codeup.com/python/dataframes/\n",
    "[2]: https://ds.codeup.com/python/advanced-dataframes/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
